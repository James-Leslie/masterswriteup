% Appendix B

\chapter{Python Code}

\label{AppendixB}

This appendix contains all of the Python code needed for the detection and placement of features in Google Street View. Each section (B.1, B.2 etc) contains all of the modules of code for each component of the final model.

\section{Image Slicing}\label{slicing}

\verb|main.py|

Perform the moving window detection on input image.

\begin{lstlisting}
from PIL import Image


def slide_window(input_file, win_ht, win_wd):

    '''inputs:
            input_file  :   str, name of image to be cropped
            win_ht        :   int, number of horizontal pixels
            win_wd        :   int, number of horizontal pixels
       outputs:
            rows x cols number of cropped images'''

    img = Image.open(input_file)

    wd = img.size[0]
    ht = img.size[1]

    cols = int(wd/win_wd)  # number of windows horizontally
    col_gap = (wd - win_wd * cols) / (cols - 1)  # whitespace between cols
    rows = int(ht/win_ht)  # number of rows vertically
    row_gap = (ht - win_ht * rows) / (rows - 1)  # whitespace between rows

    cols = cols*2 - 1  # add overlapping cols
    rows = rows*2 - 1  # add overlapping rows

    # crop image row by row
    count = 0
    for i in range(rows):
        for j in range(cols):
            # for rows 0, 2, 4 etc
            if i % 2 == 0:
                # columns 0, 2, 4 etc
                if j % 2 == 0:
                    a = int((win_wd + col_gap)*(j/2))
                    b = int((win_ht + row_gap)*(i/2))
                    c = int(a + win_wd)
                    d = int(b + win_ht)
                    count += 1

                # infill columns 1, 3, 5 etc
                else:
                    a = int(win_wd/2 + col_gap/2 + ((j-1)/2) * (win_wd + col_gap))
                    b = int((win_ht + row_gap) * (i / 2))
                    c = int(a + win_wd)
                    d = int(b + win_ht)
                    count += 1

            # infill rows 1, 3, 5 etc here
            else:
                if j % 2 == 0:
                    a = int((win_wd + col_gap)*(j/2))
                    b = int(win_ht/2 + row_gap/2 + ((i-1)/2) * (win_ht + row_gap))
                    c = int(a + win_wd)
                    d = int(b + win_ht)
                    count += 1

                # infill columns here
                else:
                    a = int(win_wd / 2 + col_gap / 2 + ((j - 1) / 2) * (win_wd + col_gap))
                    b = int(win_ht / 2 + row_gap / 2 + ((i - 1) / 2) * (win_ht + row_gap))
                    c = int(a + win_wd)
                    d = int(b + win_ht)
                    count += 1

            print(a, b, c, d)
            area = (a, b, c, d)

            cropped_img = img.crop(area)

            # find centre point of image
            hor = (a+c)/2 - 320
            vert = -((b+d)/2 - 320)

            # save_name = input_file.partition(".")[0] + "_" + str(count) + '.jpg'
            save_name = input_file.partition(".")[0] + "_" + str(count) + "_" + str(hor) + "_" + str(vert) + '.jpg'
            cropped_img.save(save_name)
\end{lstlisting}

\newpage

\section{Intersection}\label{intersection}

\verb|gauss_conformal.py|

Transform ($\phi$, $\lambda$) to (x, y)

\begin{lstlisting}
import numpy as np


# WGS84 parameters
A = 6378137.0  # semi-major axis
B = 6356752.314  # semi-minor axis
E = np.sqrt((A**2 - B**2) / A**2)  # first eccentricity
E2 = np.sqrt((A**2 - B**2) / B**2)  # second eccentricity
N = (A - B) / (A + B)
G = (A / (1 + N)) * (1 + 0.25 * (N**2) + (1/64) * (N**4))


def plane_coordinates(lat, long):
    """ given a position's latitude and longitude, return the matching x, y co-ordinates in the Hart94 datum

        inputs:
            lat, long   : latitude, longitude in decimal degrees
        outputs:
            x, y, lo"""

    # determine central meridian
    lo = 0
    if int(long) % 2 == 0:
        lo = int(long) + 1
    else:
        lo = int(long)

    # convert lat and long to radians
    lat = np.radians(lat)
    long = np.radians(long)

    # additional constants
    n = A / np.sqrt(1 - ((E**2) * (np.sin(lat)**2)))  # prime vertical radius of curvature
    eta2 = (E2**2) * (np.cos(lat)**2)
    tau = np.tan(lat)
    long_diff = np.radians(np.float64(lo)) - long  # longitude difference

    # arc length
    b1 = (3/2) * (N - (3/8) * (N**3)) * np.sin(2 * lat)
    b2 = (15/16) * ((N**2) - 0.5 * (N**4)) * np.sin(4 * lat)
    b3 = (35/48) * (N**3) * np.sin(6 * lat)
    b = G * (lat - b1 + b2 - b3)

    # x co-ordinate
    x1 = 0.5 * (long_diff**2) * n * np.sin(lat) * np.cos(lat)
    x2 = (1/24) * (long_diff**4) * n * np.sin(lat) * (np.cos(lat)**3)
    x3 = 5 + 9 * eta2 + 4 * (eta2**2) - (tau**2)
    x4 = (1/720) * (long_diff**6) * n * np.sin(lat) * (np.cos(lat)**5)
    x5 = 61 - 58 * (tau**2) + (tau**4) + 270 * eta2 - 330 * eta2 * (tau**2)
    x = b + x1 + x2 * x3 + x4 * x5

    # y co-ordinate
    y1 = long_diff * n * np.cos(lat)
    y2 = (long_diff**3) * (1/6) * n * (np.cos(lat)**3) * (1 + eta2 - (tau**2))
    y3 = (long_diff**5) * (1/120) * n * (np.cos(lat)**5) * (5 - 18 * (tau**2) + (tau**4) + 14 * eta2 - 58 * eta2 * (tau**2))
    y = y1 + y2 + y3

    return x, y, lo
\end{lstlisting}

\verb|image.py|

Defines a Python class for a Google Street View Scene with its orientation parameters.

\begin{lstlisting}
import numpy as np
import gauss_conformal as gc


class StreetScene:
    """ class used to describe a GSV image with its parameters
        latitude    :   decimal degrees
        longitude   :   decimal degrees
        heading     :   measured clockwise from North = 0
        pitch       :   measured vertically from horizontal = 0 """

    def __init__(self, latitude, longitude, heading, pitch):
        self.latitude = np.float64(latitude)
        self.longitude = np.float64(longitude)
        self.heading = np.float64(heading)
        self.pitch = np.float64(pitch)

    def lat(self):
        return self.latitude

    def long(self):
        return self.longitude

    def head(self):
        return self.heading

    def pit(self):
        return self.pitch

    def orientation(self):
        # Yaw
        rz = [[np.cos(np.radians(self.heading)), -1*np.sin(np.radians(self.heading)), 0],
              [np.sin(np.radians(self.heading)), np.cos(np.radians(self.heading)), 0],
              [0, 0, 1]]
        # Pitch
        ry = [[np.cos(np.radians(self.pitch)), 0, np.sin(np.radians(self.pitch))],
              [0, 1, 0],
              [-1*np.sin(np.radians(self.pitch)), 0, np.cos(np.radians(self.pitch))]]
        # Roll
        rx = [[1, 0, 0],
              [0, np.cos(0), -1*np.sin(0)],
              [0, np.sin(0), np.cos(0)]]

        # R = rz.ry.rx
        rotation_matrix = np.dot(rz, (np.dot(ry, rx)))
        
        return rotation_matrix
\end{lstlisting}

\verb|intersection.py|

Calculate real-world co-ordinates for a feature which has been detected in two GSV scenes.

\begin{lstlisting}
import numpy as np
import sympy as sp
import gauss_conformal as gc
import compare as comp
import image


def intersect(scene1, scene2, xs_1, ys_1, xs_2, ys_2, fov):
    """given two input street view with known camera position and orientation,
    calculate ground co-ordinates of common point

    Inputs:
        scene1, scene2  :   image.StreetScene object
        xs_1, ys_1 ...  :   observed image co-ordinates of feature in scene1 and scene2
        fov             :   field of view
    Outputs:
        xo, yo, zo      :   object co-ordinates of feature"""

    # convert from lat/long to x/y camera positions
    xc_1, yc_1, _ = gc.plane_coordinates(scene1.lat(), scene1.long())
    xc_2, yc_2, _ = gc.plane_coordinates(scene2.lat(), scene2.long())

    # calculate heading of POI in image
    head1 = scene1.head()
    head2 = scene2.head()

    head1 += (xs_1/320) * (fov/2)
    head2 += (xs_2/320) * (fov/2)

    # intersect xo, yo
    t_an = np.radians(head1)
    t_bn = np.radians(head2)
    xo_val = xc_1 + ((yc_2 - yc_1) - (xc_2 - xc_1) * np.tan(t_bn)) / (np.tan(t_an) - np.tan(t_bn))
    yo_val = yc_1 + (xo_val - xc_1) * np.tan(t_an)

    return xo_val, yo_val
\end{lstlisting}